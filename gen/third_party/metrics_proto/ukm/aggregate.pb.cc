// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: ukm/aggregate.proto

#include "ukm/aggregate.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/io/zero_copy_stream_impl_lite.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG

namespace _pb = ::PROTOBUF_NAMESPACE_ID;
namespace _pbi = _pb::internal;

namespace ukm {
PROTOBUF_CONSTEXPR Aggregate_Metric::Aggregate_Metric(
    ::_pbi::ConstantInitialized)
  : metric_hash_(uint64_t{0u})
  , value_sum_(0)
  , value_square_sum_(0)
  , total_count_(uint64_t{0u})
  , dropped_due_to_limits_(uint64_t{0u})
  , dropped_due_to_sampling_(uint64_t{0u})
  , dropped_due_to_filter_(uint64_t{0u})
  , dropped_due_to_unconfigured_(uint64_t{0u}){}
struct Aggregate_MetricDefaultTypeInternal {
  PROTOBUF_CONSTEXPR Aggregate_MetricDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~Aggregate_MetricDefaultTypeInternal() {}
  union {
    Aggregate_Metric _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT_WITH_PTR PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 Aggregate_MetricDefaultTypeInternal _Aggregate_Metric_default_instance_;
PROTOBUF_CONSTEXPR Aggregate::Aggregate(
    ::_pbi::ConstantInitialized)
  : metrics_()
  , source_id_(int64_t{0})
  , event_hash_(uint64_t{0u})
  , total_count_(uint64_t{0u})
  , dropped_due_to_limits_(uint64_t{0u})
  , dropped_due_to_sampling_(uint64_t{0u})
  , dropped_due_to_filter_(uint64_t{0u})
  , dropped_due_to_unconfigured_(uint64_t{0u}){}
struct AggregateDefaultTypeInternal {
  PROTOBUF_CONSTEXPR AggregateDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~AggregateDefaultTypeInternal() {}
  union {
    Aggregate _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT_WITH_PTR PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 AggregateDefaultTypeInternal _Aggregate_default_instance_;
}  // namespace ukm
namespace ukm {

// ===================================================================

class Aggregate_Metric::_Internal {
 public:
  using HasBits = decltype(std::declval<Aggregate_Metric>()._has_bits_);
  static void set_has_metric_hash(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
  static void set_has_value_sum(HasBits* has_bits) {
    (*has_bits)[0] |= 2u;
  }
  static void set_has_value_square_sum(HasBits* has_bits) {
    (*has_bits)[0] |= 4u;
  }
  static void set_has_total_count(HasBits* has_bits) {
    (*has_bits)[0] |= 8u;
  }
  static void set_has_dropped_due_to_limits(HasBits* has_bits) {
    (*has_bits)[0] |= 16u;
  }
  static void set_has_dropped_due_to_sampling(HasBits* has_bits) {
    (*has_bits)[0] |= 32u;
  }
  static void set_has_dropped_due_to_filter(HasBits* has_bits) {
    (*has_bits)[0] |= 64u;
  }
  static void set_has_dropped_due_to_unconfigured(HasBits* has_bits) {
    (*has_bits)[0] |= 128u;
  }
};

Aggregate_Metric::Aggregate_Metric(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::MessageLite(arena, is_message_owned) {
  SharedCtor();
  // @@protoc_insertion_point(arena_constructor:ukm.Aggregate.Metric)
}
Aggregate_Metric::Aggregate_Metric(const Aggregate_Metric& from)
  : ::PROTOBUF_NAMESPACE_ID::MessageLite(),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom<std::string>(from._internal_metadata_);
  ::memcpy(&metric_hash_, &from.metric_hash_,
    static_cast<size_t>(reinterpret_cast<char*>(&dropped_due_to_unconfigured_) -
    reinterpret_cast<char*>(&metric_hash_)) + sizeof(dropped_due_to_unconfigured_));
  // @@protoc_insertion_point(copy_constructor:ukm.Aggregate.Metric)
}

inline void Aggregate_Metric::SharedCtor() {
::memset(reinterpret_cast<char*>(this) + static_cast<size_t>(
    reinterpret_cast<char*>(&metric_hash_) - reinterpret_cast<char*>(this)),
    0, static_cast<size_t>(reinterpret_cast<char*>(&dropped_due_to_unconfigured_) -
    reinterpret_cast<char*>(&metric_hash_)) + sizeof(dropped_due_to_unconfigured_));
}

Aggregate_Metric::~Aggregate_Metric() {
  // @@protoc_insertion_point(destructor:ukm.Aggregate.Metric)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<std::string>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void Aggregate_Metric::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void Aggregate_Metric::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void Aggregate_Metric::Clear() {
// @@protoc_insertion_point(message_clear_start:ukm.Aggregate.Metric)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x000000ffu) {
    ::memset(&metric_hash_, 0, static_cast<size_t>(
        reinterpret_cast<char*>(&dropped_due_to_unconfigured_) -
        reinterpret_cast<char*>(&metric_hash_)) + sizeof(dropped_due_to_unconfigured_));
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear<std::string>();
}

const char* Aggregate_Metric::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  _Internal::HasBits has_bits{};
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // optional fixed64 metric_hash = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 9)) {
          _Internal::set_has_metric_hash(&has_bits);
          metric_hash_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<uint64_t>(ptr);
          ptr += sizeof(uint64_t);
        } else
          goto handle_unusual;
        continue;
      // optional double value_sum = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 17)) {
          _Internal::set_has_value_sum(&has_bits);
          value_sum_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<double>(ptr);
          ptr += sizeof(double);
        } else
          goto handle_unusual;
        continue;
      // optional double value_square_sum = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 25)) {
          _Internal::set_has_value_square_sum(&has_bits);
          value_square_sum_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<double>(ptr);
          ptr += sizeof(double);
        } else
          goto handle_unusual;
        continue;
      // optional uint64 total_count = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          _Internal::set_has_total_count(&has_bits);
          total_count_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional uint64 dropped_due_to_limits = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 40)) {
          _Internal::set_has_dropped_due_to_limits(&has_bits);
          dropped_due_to_limits_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional uint64 dropped_due_to_sampling = 6;
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 48)) {
          _Internal::set_has_dropped_due_to_sampling(&has_bits);
          dropped_due_to_sampling_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional uint64 dropped_due_to_filter = 8;
      case 8:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 64)) {
          _Internal::set_has_dropped_due_to_filter(&has_bits);
          dropped_due_to_filter_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional uint64 dropped_due_to_unconfigured = 9;
      case 9:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 72)) {
          _Internal::set_has_dropped_due_to_unconfigured(&has_bits);
          dropped_due_to_unconfigured_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<std::string>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  _has_bits_.Or(has_bits);
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* Aggregate_Metric::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:ukm.Aggregate.Metric)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // optional fixed64 metric_hash = 1;
  if (cached_has_bits & 0x00000001u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFixed64ToArray(1, this->_internal_metric_hash(), target);
  }

  // optional double value_sum = 2;
  if (cached_has_bits & 0x00000002u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteDoubleToArray(2, this->_internal_value_sum(), target);
  }

  // optional double value_square_sum = 3;
  if (cached_has_bits & 0x00000004u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteDoubleToArray(3, this->_internal_value_square_sum(), target);
  }

  // optional uint64 total_count = 4;
  if (cached_has_bits & 0x00000008u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(4, this->_internal_total_count(), target);
  }

  // optional uint64 dropped_due_to_limits = 5;
  if (cached_has_bits & 0x00000010u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(5, this->_internal_dropped_due_to_limits(), target);
  }

  // optional uint64 dropped_due_to_sampling = 6;
  if (cached_has_bits & 0x00000020u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(6, this->_internal_dropped_due_to_sampling(), target);
  }

  // optional uint64 dropped_due_to_filter = 8;
  if (cached_has_bits & 0x00000040u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(8, this->_internal_dropped_due_to_filter(), target);
  }

  // optional uint64 dropped_due_to_unconfigured = 9;
  if (cached_has_bits & 0x00000080u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(9, this->_internal_dropped_due_to_unconfigured(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = stream->WriteRaw(_internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).data(),
        static_cast<int>(_internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).size()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:ukm.Aggregate.Metric)
  return target;
}

size_t Aggregate_Metric::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:ukm.Aggregate.Metric)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x000000ffu) {
    // optional fixed64 metric_hash = 1;
    if (cached_has_bits & 0x00000001u) {
      total_size += 1 + 8;
    }

    // optional double value_sum = 2;
    if (cached_has_bits & 0x00000002u) {
      total_size += 1 + 8;
    }

    // optional double value_square_sum = 3;
    if (cached_has_bits & 0x00000004u) {
      total_size += 1 + 8;
    }

    // optional uint64 total_count = 4;
    if (cached_has_bits & 0x00000008u) {
      total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_total_count());
    }

    // optional uint64 dropped_due_to_limits = 5;
    if (cached_has_bits & 0x00000010u) {
      total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_dropped_due_to_limits());
    }

    // optional uint64 dropped_due_to_sampling = 6;
    if (cached_has_bits & 0x00000020u) {
      total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_dropped_due_to_sampling());
    }

    // optional uint64 dropped_due_to_filter = 8;
    if (cached_has_bits & 0x00000040u) {
      total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_dropped_due_to_filter());
    }

    // optional uint64 dropped_due_to_unconfigured = 9;
    if (cached_has_bits & 0x00000080u) {
      total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_dropped_due_to_unconfigured());
    }

  }
  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    total_size += _internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).size();
  }
  int cached_size = ::_pbi::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void Aggregate_Metric::CheckTypeAndMergeFrom(
    const ::PROTOBUF_NAMESPACE_ID::MessageLite& from) {
  MergeFrom(*::_pbi::DownCast<const Aggregate_Metric*>(
      &from));
}

void Aggregate_Metric::MergeFrom(const Aggregate_Metric& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:ukm.Aggregate.Metric)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 0x000000ffu) {
    if (cached_has_bits & 0x00000001u) {
      metric_hash_ = from.metric_hash_;
    }
    if (cached_has_bits & 0x00000002u) {
      value_sum_ = from.value_sum_;
    }
    if (cached_has_bits & 0x00000004u) {
      value_square_sum_ = from.value_square_sum_;
    }
    if (cached_has_bits & 0x00000008u) {
      total_count_ = from.total_count_;
    }
    if (cached_has_bits & 0x00000010u) {
      dropped_due_to_limits_ = from.dropped_due_to_limits_;
    }
    if (cached_has_bits & 0x00000020u) {
      dropped_due_to_sampling_ = from.dropped_due_to_sampling_;
    }
    if (cached_has_bits & 0x00000040u) {
      dropped_due_to_filter_ = from.dropped_due_to_filter_;
    }
    if (cached_has_bits & 0x00000080u) {
      dropped_due_to_unconfigured_ = from.dropped_due_to_unconfigured_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
  _internal_metadata_.MergeFrom<std::string>(from._internal_metadata_);
}

void Aggregate_Metric::CopyFrom(const Aggregate_Metric& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:ukm.Aggregate.Metric)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool Aggregate_Metric::IsInitialized() const {
  return true;
}

void Aggregate_Metric::InternalSwap(Aggregate_Metric* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(Aggregate_Metric, dropped_due_to_unconfigured_)
      + sizeof(Aggregate_Metric::dropped_due_to_unconfigured_)
      - PROTOBUF_FIELD_OFFSET(Aggregate_Metric, metric_hash_)>(
          reinterpret_cast<char*>(&metric_hash_),
          reinterpret_cast<char*>(&other->metric_hash_));
}

std::string Aggregate_Metric::GetTypeName() const {
  return "ukm.Aggregate.Metric";
}


// ===================================================================

class Aggregate::_Internal {
 public:
  using HasBits = decltype(std::declval<Aggregate>()._has_bits_);
  static void set_has_source_id(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
  static void set_has_event_hash(HasBits* has_bits) {
    (*has_bits)[0] |= 2u;
  }
  static void set_has_total_count(HasBits* has_bits) {
    (*has_bits)[0] |= 4u;
  }
  static void set_has_dropped_due_to_limits(HasBits* has_bits) {
    (*has_bits)[0] |= 8u;
  }
  static void set_has_dropped_due_to_sampling(HasBits* has_bits) {
    (*has_bits)[0] |= 16u;
  }
  static void set_has_dropped_due_to_filter(HasBits* has_bits) {
    (*has_bits)[0] |= 32u;
  }
  static void set_has_dropped_due_to_unconfigured(HasBits* has_bits) {
    (*has_bits)[0] |= 64u;
  }
};

Aggregate::Aggregate(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::MessageLite(arena, is_message_owned),
  metrics_(arena) {
  SharedCtor();
  // @@protoc_insertion_point(arena_constructor:ukm.Aggregate)
}
Aggregate::Aggregate(const Aggregate& from)
  : ::PROTOBUF_NAMESPACE_ID::MessageLite(),
      _has_bits_(from._has_bits_),
      metrics_(from.metrics_) {
  _internal_metadata_.MergeFrom<std::string>(from._internal_metadata_);
  ::memcpy(&source_id_, &from.source_id_,
    static_cast<size_t>(reinterpret_cast<char*>(&dropped_due_to_unconfigured_) -
    reinterpret_cast<char*>(&source_id_)) + sizeof(dropped_due_to_unconfigured_));
  // @@protoc_insertion_point(copy_constructor:ukm.Aggregate)
}

inline void Aggregate::SharedCtor() {
::memset(reinterpret_cast<char*>(this) + static_cast<size_t>(
    reinterpret_cast<char*>(&source_id_) - reinterpret_cast<char*>(this)),
    0, static_cast<size_t>(reinterpret_cast<char*>(&dropped_due_to_unconfigured_) -
    reinterpret_cast<char*>(&source_id_)) + sizeof(dropped_due_to_unconfigured_));
}

Aggregate::~Aggregate() {
  // @@protoc_insertion_point(destructor:ukm.Aggregate)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<std::string>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void Aggregate::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void Aggregate::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void Aggregate::Clear() {
// @@protoc_insertion_point(message_clear_start:ukm.Aggregate)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  metrics_.Clear();
  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x0000007fu) {
    ::memset(&source_id_, 0, static_cast<size_t>(
        reinterpret_cast<char*>(&dropped_due_to_unconfigured_) -
        reinterpret_cast<char*>(&source_id_)) + sizeof(dropped_due_to_unconfigured_));
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear<std::string>();
}

const char* Aggregate::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  _Internal::HasBits has_bits{};
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // optional int64 source_id = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _Internal::set_has_source_id(&has_bits);
          source_id_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional fixed64 event_hash = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 17)) {
          _Internal::set_has_event_hash(&has_bits);
          event_hash_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<uint64_t>(ptr);
          ptr += sizeof(uint64_t);
        } else
          goto handle_unusual;
        continue;
      // optional uint64 total_count = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _Internal::set_has_total_count(&has_bits);
          total_count_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional uint64 dropped_due_to_limits = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          _Internal::set_has_dropped_due_to_limits(&has_bits);
          dropped_due_to_limits_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional uint64 dropped_due_to_sampling = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 40)) {
          _Internal::set_has_dropped_due_to_sampling(&has_bits);
          dropped_due_to_sampling_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated .ukm.Aggregate.Metric metrics = 6;
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 50)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_metrics(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<50>(ptr));
        } else
          goto handle_unusual;
        continue;
      // optional uint64 dropped_due_to_filter = 8;
      case 8:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 64)) {
          _Internal::set_has_dropped_due_to_filter(&has_bits);
          dropped_due_to_filter_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional uint64 dropped_due_to_unconfigured = 9;
      case 9:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 72)) {
          _Internal::set_has_dropped_due_to_unconfigured(&has_bits);
          dropped_due_to_unconfigured_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<std::string>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  _has_bits_.Or(has_bits);
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* Aggregate::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:ukm.Aggregate)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // optional int64 source_id = 1;
  if (cached_has_bits & 0x00000001u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt64ToArray(1, this->_internal_source_id(), target);
  }

  // optional fixed64 event_hash = 2;
  if (cached_has_bits & 0x00000002u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFixed64ToArray(2, this->_internal_event_hash(), target);
  }

  // optional uint64 total_count = 3;
  if (cached_has_bits & 0x00000004u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(3, this->_internal_total_count(), target);
  }

  // optional uint64 dropped_due_to_limits = 4;
  if (cached_has_bits & 0x00000008u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(4, this->_internal_dropped_due_to_limits(), target);
  }

  // optional uint64 dropped_due_to_sampling = 5;
  if (cached_has_bits & 0x00000010u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(5, this->_internal_dropped_due_to_sampling(), target);
  }

  // repeated .ukm.Aggregate.Metric metrics = 6;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_metrics_size()); i < n; i++) {
    const auto& repfield = this->_internal_metrics(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(6, repfield, repfield.GetCachedSize(), target, stream);
  }

  // optional uint64 dropped_due_to_filter = 8;
  if (cached_has_bits & 0x00000020u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(8, this->_internal_dropped_due_to_filter(), target);
  }

  // optional uint64 dropped_due_to_unconfigured = 9;
  if (cached_has_bits & 0x00000040u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(9, this->_internal_dropped_due_to_unconfigured(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = stream->WriteRaw(_internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).data(),
        static_cast<int>(_internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).size()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:ukm.Aggregate)
  return target;
}

size_t Aggregate::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:ukm.Aggregate)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .ukm.Aggregate.Metric metrics = 6;
  total_size += 1UL * this->_internal_metrics_size();
  for (const auto& msg : this->metrics_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x0000007fu) {
    // optional int64 source_id = 1;
    if (cached_has_bits & 0x00000001u) {
      total_size += ::_pbi::WireFormatLite::Int64SizePlusOne(this->_internal_source_id());
    }

    // optional fixed64 event_hash = 2;
    if (cached_has_bits & 0x00000002u) {
      total_size += 1 + 8;
    }

    // optional uint64 total_count = 3;
    if (cached_has_bits & 0x00000004u) {
      total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_total_count());
    }

    // optional uint64 dropped_due_to_limits = 4;
    if (cached_has_bits & 0x00000008u) {
      total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_dropped_due_to_limits());
    }

    // optional uint64 dropped_due_to_sampling = 5;
    if (cached_has_bits & 0x00000010u) {
      total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_dropped_due_to_sampling());
    }

    // optional uint64 dropped_due_to_filter = 8;
    if (cached_has_bits & 0x00000020u) {
      total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_dropped_due_to_filter());
    }

    // optional uint64 dropped_due_to_unconfigured = 9;
    if (cached_has_bits & 0x00000040u) {
      total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_dropped_due_to_unconfigured());
    }

  }
  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    total_size += _internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).size();
  }
  int cached_size = ::_pbi::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void Aggregate::CheckTypeAndMergeFrom(
    const ::PROTOBUF_NAMESPACE_ID::MessageLite& from) {
  MergeFrom(*::_pbi::DownCast<const Aggregate*>(
      &from));
}

void Aggregate::MergeFrom(const Aggregate& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:ukm.Aggregate)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  metrics_.MergeFrom(from.metrics_);
  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 0x0000007fu) {
    if (cached_has_bits & 0x00000001u) {
      source_id_ = from.source_id_;
    }
    if (cached_has_bits & 0x00000002u) {
      event_hash_ = from.event_hash_;
    }
    if (cached_has_bits & 0x00000004u) {
      total_count_ = from.total_count_;
    }
    if (cached_has_bits & 0x00000008u) {
      dropped_due_to_limits_ = from.dropped_due_to_limits_;
    }
    if (cached_has_bits & 0x00000010u) {
      dropped_due_to_sampling_ = from.dropped_due_to_sampling_;
    }
    if (cached_has_bits & 0x00000020u) {
      dropped_due_to_filter_ = from.dropped_due_to_filter_;
    }
    if (cached_has_bits & 0x00000040u) {
      dropped_due_to_unconfigured_ = from.dropped_due_to_unconfigured_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
  _internal_metadata_.MergeFrom<std::string>(from._internal_metadata_);
}

void Aggregate::CopyFrom(const Aggregate& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:ukm.Aggregate)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool Aggregate::IsInitialized() const {
  return true;
}

void Aggregate::InternalSwap(Aggregate* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  metrics_.InternalSwap(&other->metrics_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(Aggregate, dropped_due_to_unconfigured_)
      + sizeof(Aggregate::dropped_due_to_unconfigured_)
      - PROTOBUF_FIELD_OFFSET(Aggregate, source_id_)>(
          reinterpret_cast<char*>(&source_id_),
          reinterpret_cast<char*>(&other->source_id_));
}

std::string Aggregate::GetTypeName() const {
  return "ukm.Aggregate";
}


// @@protoc_insertion_point(namespace_scope)
}  // namespace ukm
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::ukm::Aggregate_Metric*
Arena::CreateMaybeMessage< ::ukm::Aggregate_Metric >(Arena* arena) {
  return Arena::CreateMessageInternal< ::ukm::Aggregate_Metric >(arena);
}
template<> PROTOBUF_NOINLINE ::ukm::Aggregate*
Arena::CreateMaybeMessage< ::ukm::Aggregate >(Arena* arena) {
  return Arena::CreateMessageInternal< ::ukm::Aggregate >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
